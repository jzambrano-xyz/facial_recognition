{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reconocimiento facial Open CV",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOP4q7zkIk7PBRru7ZuP4UP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jzambrano-xyz/facial_recognition/blob/main/Reconocimiento_facial_Open_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20PZiT19GLTw"
      },
      "source": [
        "# Captura de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X37VQE8zBbkG",
        "outputId": "6d1c64e8-e9ce-4200-c0ac-e18d9f1acc2e"
      },
      "source": [
        "! pip install opencv-python\n",
        "! pip install imutils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WNX9JtNEHa4"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "\n",
        "personName = 'Julio'\n",
        "dataPath = '/content/reconocimiento'#Cambia a la ruta donde hayas almacenado Data\n",
        "personPath = dataPath + '/' + personName\n",
        "\n",
        "if not os.path.exists(personPath):\n",
        "    print('Carpeta creada: ',personPath)\n",
        "    os.makedirs(personPath)\n",
        "\n",
        "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
        "#cap = cv2.VideoCapture('Video.mp4')\n",
        "\n",
        "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
        "count = 0\n",
        "\n",
        "while True:\n",
        "    \n",
        "    ret, frame = cap.read()\n",
        "    if ret == False: break\n",
        "    frame =  imutils.resize(frame, width=640)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    auxFrame = frame.copy()\n",
        "\n",
        "    faces = faceClassif.detectMultiScale(gray,1.3,5)\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
        "        rostro = auxFrame[y:y+h,x:x+w]\n",
        "        rostro = cv2.resize(rostro,(150,150),interpolation=cv2.INTER_CUBIC)\n",
        "        cv2.imwrite(personPath + '/rostro_{}.jpg'.format(count),rostro)\n",
        "        count = count + 1\n",
        "    cv2.imshow('frame',frame)\n",
        "\n",
        "    k =  cv2.waitKey(1)\n",
        "    if k == 27 or count >= 300:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLLgKykrGICo"
      },
      "source": [
        "# Etiquetado de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZFZSWwGGTza",
        "outputId": "7a7ce63e-c26f-4d79-bde1-6ee4fd7c618f"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "dataPath = '/content/reconocimiento'#Cambia a la ruta donde hayas almacenado Data\n",
        "peopleList = os.listdir(dataPath)\n",
        "print('Lista de personas: ', peopleList)\n",
        "\n",
        "labels = []\n",
        "facesData = []\n",
        "label = 0\n",
        "\n",
        "for nameDir in peopleList:\n",
        "    personPath = dataPath + '/' + nameDir\n",
        "    print('Leyendo las imágenes')\n",
        "\n",
        "    for fileName in os.listdir(personPath):\n",
        "        print('Rostros: ', nameDir + '/' + fileName)\n",
        "        labels.append(label)\n",
        "        facesData.append(cv2.imread(personPath+'/'+fileName,0))\n",
        "        #image = cv2.imread(personPath+'/'+fileName,0)\n",
        "        #cv2.imshow('image',image)\n",
        "        #cv2.waitKey(10)\n",
        "    label = label + 1\n",
        "\n",
        "#print('labels= ',labels)\n",
        "#print('Número de etiquetas 0: ',np.count_nonzero(np.array(labels)==0))\n",
        "#print('Número de etiquetas 1: ',np.count_nonzero(np.array(labels)==1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lista de personas:  ['Julio']\n",
            "Leyendo las imágenes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN93YXJQGtJ_"
      },
      "source": [
        "# Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcqjadDZGuzX"
      },
      "source": [
        "# Métodos para entrenar el reconocedor\n",
        "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
        "face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
        "#face_recognizer = cv2.face.LBPHFaceRecognizer_create()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "P-M0jNDkG5r7",
        "outputId": "c713272e-ee3b-4464-b229-5781ffec6275"
      },
      "source": [
        "# Entrenando el reconocedor de rostros\n",
        "print(\"Entrenando...\")\n",
        "face_recognizer.train(facesData, np.array(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f7b5473dc17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entrenando el reconocedor de rostros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Entrenando...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mface_recognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacesData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv_contrib/modules/face/src/fisher_faces.cpp:71: error: (-5:Bad argument) Empty training data was given. You'll need more than one sample to learn a model. in function 'train'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP3AWU3dG8wY"
      },
      "source": [
        "# Almacenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiYhbMdtG_-9"
      },
      "source": [
        "# Almacenando el modelo obtenido\n",
        "#face_recognizer.write('modeloEigenFace.xml')\n",
        "face_recognizer.write('modeloFisherFace.xml')\n",
        "#face_recognizer.write('modeloLBPHFace.xml')\n",
        "print(\"Modelo almacenado...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDKXW3X-HJ0r"
      },
      "source": [
        "# Reconocimiento facial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvrmKFdsHMY5"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "dataPath = '/Reconocimiento Facial/Data' #Cambia a la ruta donde hayas almacenado Data\n",
        "imagePaths = os.listdir(dataPath)\n",
        "print('imagePaths=',imagePaths)\n",
        "\n",
        "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
        "face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
        "#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "# Leyendo el modelo\n",
        "#face_recognizer.read('modeloEigenFace.xml')\n",
        "face_recognizer.read('modeloFisherFace.xml')\n",
        "#face_recognizer.read('modeloLBPHFace.xml')\n",
        "\n",
        "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
        "#cap = cv2.VideoCapture('Video.mp4')\n",
        "\n",
        "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
        "\n",
        "while True:\n",
        "    ret,frame = cap.read()\n",
        "    if ret == False: break\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    auxFrame = gray.copy()\n",
        "\n",
        "    faces = faceClassif.detectMultiScale(gray,1.3,5)\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "        rostro = auxFrame[y:y+h,x:x+w]\n",
        "        rostro = cv2.resize(rostro,(150,150),interpolation= cv2.INTER_CUBIC)\n",
        "        result = face_recognizer.predict(rostro)\n",
        "\n",
        "        cv2.putText(frame,'{}'.format(result),(x,y-5),1,1.3,(255,255,0),1,cv2.LINE_AA)\n",
        "        '''\n",
        "        # EigenFaces\n",
        "        if result[1] < 5700:\n",
        "            cv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
        "            cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
        "        else:\n",
        "            cv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
        "            cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
        "        '''\n",
        "        # FisherFace\n",
        "        if result[1] < 500:\n",
        "            cv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
        "            cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
        "        else:\n",
        "            cv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
        "            cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
        "        '''\n",
        "        # LBPHFace\n",
        "        if result[1] < 70:\n",
        "            cv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
        "            cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
        "        else:\n",
        "            cv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
        "            cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
        "        '''\n",
        "    cv2.imshow('frame',frame)\n",
        "    k = cv2.waitKey(1)\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}